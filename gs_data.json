{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "e2c7Kt0AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Zipeng Dai", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=e2c7Kt0AAAAJ&citpid=6", "affiliation": "Beijing Institute of Technology", "organization": 13321754382075750808, "interests": ["deep reinforcement learning", "mobile crowdsensing", "unmanned vehicle"], "email_domain": "@bit.edu.cn", "homepage": "https://www.zipengdai.com/", "citedby": 530, "publications": {"e2c7Kt0AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Distributed and energy-efficient mobile crowdsensing with charging stations by deep reinforcement learning", "pub_year": "2019"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:u5HHmVD_uO8C", "num_citations": 131, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10052052707337875143", "cites_id": ["10052052707337875143"]}, "e2c7Kt0AAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Delay-sensitive energy-efficient UAV crowdsensing by deep reinforcement learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:IjCSPb-OGe4C", "num_citations": 71, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1207179895167038282", "cites_id": ["1207179895167038282"]}, "e2c7Kt0AAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AoI-minimal UAV crowdsensing by model-based graph convolutional reinforcement learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:Tyk-4Ss8FVUC", "num_citations": 65, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4401227194743749997", "cites_id": ["4401227194743749997"]}, "e2c7Kt0AAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-task-oriented vehicular crowdsensing: A deep learning approach", "pub_year": "2020"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:9yKSN-GCB0IC", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10475354102644164824", "cites_id": ["10475354102644164824"]}, "e2c7Kt0AAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mobile crowdsensing for data freshness: A deep reinforcement learning approach", "pub_year": "2021"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:qjMakFHDy7sC", "num_citations": 42, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9731968652503072452", "cites_id": ["9731968652503072452"]}, "e2c7Kt0AAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Time-aware location prediction by convolutional area-of-interest modeling and memory-augmented attentive lstm", "pub_year": "2020"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:d1gkVwhDpl0C", "num_citations": 32, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3121379138324293962", "cites_id": ["3121379138324293962"]}, "e2c7Kt0AAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Curiosity-driven energy-efficient worker scheduling in vehicular crowdsourcing: A deep reinforcement learning approach", "pub_year": "2020"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:u-x6o8ySG0sC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7771470688408440734", "cites_id": ["7771470688408440734"]}, "e2c7Kt0AAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Energy-efficient 3D vehicular crowdsourcing for disaster response by distributed deep reinforcement learning", "pub_year": "2021"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:UeHWp8X0CEIC", "num_citations": 23, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18123974253413864706", "cites_id": ["18123974253413864706"]}, "e2c7Kt0AAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring both individuality and cooperation for air-ground spatial crowdsourcing by multi-agent deep reinforcement learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:roLk4NBRz8UC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18338101265990845680", "cites_id": ["18338101265990845680"]}, "e2c7Kt0AAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "QoI-aware mobile crowdsensing for metaverse by multi-agent deep reinforcement learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:UebtZRa9Y70C", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=574787644954887176", "cites_id": ["574787644954887176"]}, "e2c7Kt0AAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Socially-attentive policy optimization in multi-agent self-driving system", "pub_year": "2023"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:LkGwnXOMwfcC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10363471755334087704", "cites_id": ["10363471755334087704"]}, "e2c7Kt0AAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning to shape rewards using a game of two partners", "pub_year": "2023"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:WF5omc3nYNoC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2724759105135043079", "cites_id": ["2724759105135043079"]}, "e2c7Kt0AAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Cooperative multiagent transfer learning with coalition pattern decomposition", "pub_year": "2023"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:0EnyYjriUFMC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=996256750108072559", "cites_id": ["996256750108072559"]}, "e2c7Kt0AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Timing is Everything: Learning to act selectively with costly actions and budgetary constraints", "pub_year": "2022"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:eQOLeE2rZwMC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4566369965107348384", "cites_id": ["4566369965107348384"]}, "e2c7Kt0AAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Hibid: A cross-channel constrained bidding system with budget allocation by hierarchical offline deep reinforcement learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:Se3iqnhoufwC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15835416767818930078", "cites_id": ["15835416767818930078"]}, "e2c7Kt0AAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Taming multi-agent reinforcement learning with estimator variance reduction", "pub_year": "2022"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:hqOjcs7Dif8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1411016958010297966", "cites_id": ["1411016958010297966"]}, "e2c7Kt0AAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "UavNetSim-v1: A Python-based Simulation Platform for UAV Communication Networks", "pub_year": "2025"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:MXK_kJrjxJIC", "num_citations": 0}, "e2c7Kt0AAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation", "pub_year": "2025"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:8k81kl-MbHgC", "num_citations": 0}, "e2c7Kt0AAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CuDA2: An approach for Incorporating Traitor Agents into Cooperative Multi-Agent Systems", "pub_year": "2024"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:5nxA0vEk-isC", "num_citations": 0}, "e2c7Kt0AAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Semi-Centralised Multi-Agent Reinforcement Learning with Policy-Embedded Training", "pub_year": "2022"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:Y0pCki6q_DkC", "num_citations": 0}, "e2c7Kt0AAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "深度强化学习：学术前沿与实战应用", "pub_year": "2020"}, "filled": false, "author_pub_id": "e2c7Kt0AAAAJ:2osOgNQ5qMEC", "num_citations": 0}}, "citedby5y": 528, "hindex": 11, "hindex5y": 11, "i10index": 12, "i10index5y": 12, "cites_per_year": {"2020": 16, "2021": 43, "2022": 57, "2023": 121, "2024": 189, "2025": 102}, "updated": "2025-07-25 16:20:46.405065"}